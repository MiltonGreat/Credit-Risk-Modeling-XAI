# Credit Risk Modeling with Explainable AI (XAI)

![screenshot-localhost_8888-2025 04 11-13_05_12](https://github.com/user-attachments/assets/4e9a33b8-3956-403b-b284-d67b53c4df90)

### Overview

This project successfully developed a machine learning model to predict credit default risk while leveraging Explainable AI (XAI) techniques (SHAP, LIME, counterfactuals) to ensure transparency and regulatory compliance. 

The goal is to predict whether a borrower will default (SeriousDlqin2yrs = 1) based on financial behavior.

### Dataset

Target: SeriousDlqin2yrs (1 = default within 2 years, 0 = no default)

**Key Features Used**

- Feature Risk Impact
- RevolvingUtilizationOfUnsecuredLines (High)
- TotalPastDue (engineered) (Very High)
- NumberOfTimes90DaysLate (High)
- MonthlyIncome (Medium)
- age (Low)

### Key Steps

1. Data Preparation
- Handled missing values (median imputation).
- Capped outliers (1st/99th percentiles).
- Feature engineering (e.g., aggregated past-due metrics).

2. Model Training
- Logistic Regression
- Random Forest
- Gradient Boosting (Best AUC: 0.8658)
- XGBoost
- AUC-ROC, Precision-Recall, Calibration Plots

3. Explainability (XAI)
- SHAP - Global feature importance - Identified TotalPastDue as the top risk factor
- LIME - Local explanations for individual predictions - Explained why a specific applicant was rejected
- Counterfactuals	- "What-if" scenarios for rejections - "Clearing 2 late payments reduces risk from 58% â†’ 3%"

### Key Findings

- Best Model: Gradient Boosting (AUC = 0.866) outperformed others.

Top Risk Factors:

- TotalPastDue (59.2% impact)
- RevolvingUtilizationOfUnsecuredLines (15.9%)
- NumberOfTimes90DaysLate (13.8%)

### Conclusion

In summary, this project demonstrates that AI-driven credit risk models can be both accurate and interpretable, enabling fairer lending decisions while maintaining profitability.

[Give Me Some Credit Dataset from Kaggle](https://www.kaggle.com/c/GiveMeSomeCredit)

